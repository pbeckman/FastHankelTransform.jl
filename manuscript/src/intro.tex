
The Fast Fourier Transform (FFT) has revolutionized a wide range of fields in
mathematics, engineering, physics, etc., by enabling various signal processing
and Fourier analysis tasks to be performed using a computational cost which
scales quasi-linearly with the number of data points~$N$, up to Nyquist sampling
constraints. However, the FFT is an algebraic algorithm, and requires that the
input signal be sampled at equispaced points in time and that the desired output
frequencies are equispaced on the integers. These assumptions are frequently not
met in many applications, such as adaptive numerical PDE solvers~\cite{},
magnetic resonance imaging data acquisition~\cite{}, and various signal
processing tasks~\cite{}. To overcome this setback, Nonuniform FFT (NUFFT)
algorithms have been developed~\cite{}. We will not provide a thorough overview
of NUFFT algorithms, but merely say that multiple software libraries~\cite{}
have been released which achieve near FFT speeds in one dimension, assuming that
the distribution of time samples and frequency outputs is not pathological. In
higher dimensions, NUFFTs are less competitive with standard FFTs, but the
computational task at hand is also significantly harder.

The FFT grew out of a need to perform Fourier analysis in Cartesian coordinates.
However, depending on the particular problem, the associated continuous Fourier
analysis might be better suited to other coordinate systems. One such commonly
encountered situation is taking the Fourier transform of radially symmetric
functions in dimensions~$ d \geq 2$. This arises frequently in spatial
statistics~\cite{}, fast algorithms for PDEs~\cite{}, and imaging~\cite{}. For
example, in two dimensions, the Fourier transform of a function~$f$ is given as:
\begin{equation}
  g(\omega_1, \omega_2) = \frac{1}{4\pi^2} \iint_{\R^2} f(x_1, x_2) \, 
  e^{-i(\omega_1 x_1 + \omega_2 x_2)}  \, dx_1 \, dx_2.
\end{equation}
Transforming to polar coordinates~$(\omega_1,\omega_2) \mapsto (\rho,\alpha)$
and~$(x_1,x_2) \mapsto (r,\theta)$ the above expression becomes
\begin{equation}
  \label{eq:ftpolar}
  \begin{aligned}
    g(\rho, \alpha) &= \frac{1}{4\pi^2} \iint_{\R^2} 
    f(r,\theta) \, 
    e^{-i \rho r (\cos\alpha \cos\theta + \sin\alpha \sin\theta) } 
    \, r \, dr \, d\theta \\
  &= \frac{1}{4\pi^2} \int_0^{2\pi} \int_0^\infty f(r,\theta) \, e^{-i \rho r \cos(\alpha-\theta) } \, r \, dr \, d\theta.
  \end{aligned}
\end{equation}
Furthermore, if~$f$ is radially symmetric, i.e.~$f = f(r)$, then the above
transform can be written as
\begin{equation}
  \label{eq:HT}
  \begin{aligned}
  g(\rho,\alpha) &= \frac{1}{4\pi^2} \int_0^\infty f(r) \, r \int_0^{2\pi} 
  e^{-i \rho r \cos(\alpha - \theta) }  \, d\theta \, dr \\
  &= \frac{1}{2\pi} \int_0^\infty f(r) \, r \, J_0(\rho r)  \, dr,
  \end{aligned}
\end{equation}
where we have used the integral representation of the zeroth-order Bessel
function~\cite{olver2010nist}:
\begin{equation}
  J_0(x) 
  = \frac{1}{\pi} \int_0^\pi \cos \left( x \cos \theta \right) \, d\theta.
\end{equation}
The integral involving~$J_0$ in equation~\eqref{eq:HT} is known as a
\emph{Hankel Transform} of order 0 --- usually referred to simply as a Hankel
Transform. In higher ambient dimensions, the Fourier transform of radially
symmetric functions reduces to Hankel transforms of higher orders, a case which
we discuss toward the end of this manuscript. Similarly, if the function~$f$
in~\eqref{eq:ftpolar} has a particular periodicity dependence in~~$\theta$,
e.g.~$f = f(r)e^{im\theta}$, then we have
\begin{equation}
  \begin{aligned}
  g(\rho,\alpha) &= \frac{1}{4\pi^2} \int_0^\infty f(r) \, r \int_0^{2\pi} 
  e^{-i \rho r \cos(\alpha - \theta) } \, e^{im\theta}  \, d\theta \, dr \\
  &= \frac{i^m}{2\pi} \int_0^\infty f(r) \, r \, J_m(\rho r)  \, dr,
  \end{aligned}
\end{equation}
where, again, we have invoked an integral representation
for~$J_m$~\cite{olver2010nist}. 
It main result of this work is an algorithm for rapidly evaluating a discretized
version of the above integral at a collection of~$\rho_j$.
For now, we will focus on the standard
(zeroth-order) Hankel transform, and return to these higher order transforms
toward the end of the paper.

In order to numerically compute~$g$ in~\eqref{eq:HT} at a collection of~$M$
``frequencies''~$\rho_j$'s, the Hankel transform must be discretized using an
appropriate quadrature that depends on the particular class of~$f$ for which the
integral is desired. Ignoring various corner cases, this results in the need for
computing
\begin{equation} \label{eq:DHT}
  \begin{aligned}
  g(\rho_j) \approx 
  g_j &:= \sum_{k=1}^N w_k \, f(r_k) \, r_k \, J_0(\rho_j r_k) \\
  &\ = \sum_{k=1}^N c_k \, J_0(\rho_j r_k),
   \qquad \text{for } j = 1, \ldots, M.
  \end{aligned}
\end{equation}
The above sum will be referred to as the Discrete Hankel Transform (DHT). 

In our motivating example --- computing the continuous Fourier transform --- the
DHT arises from the discretization of the associated Fourier integral. The DHT
also arises in other circumstances, including imaging~\cite{higgins1988hankel,
zhao2013fourier}, partial differential
equations~\cite{bisseling1985fast,ali1999generalized}, and
statistics~\cite{lord1954a, genton2002nonparametric}. In many such applications,
a fully nonuniform DHT is desired, as the relevant frequencies $\rho_j$ may not
be equispaced, and the most efficient quadrature rule for
discretizing~\eqref{eq:HT} may also have nodes~$r_k$ which not equispaced. In
what follows, it is enough to merely consider the above sum with the
coefficients~$c_k$. The algorithm of this work allows for arbitrary selection of
the frequencies~$\rho_j$ and nodes~$r_k$, in contrast to other algorithms which
require some structure to their location (e.g. equispaced). There are a few
types of commonly encountered DHTs, all of which our algorithm can address.
Schl\"omilch expansions~\cite{} are of the form
\begin{equation}
  \label{eq:expan}
  f_k = \sum_{j = 1}^M g_j \, J_0(\rho_j r_k),
\end{equation}
where~$r_k \in [0,1]$ and the frequencies are chosen as~$\rho_j = j\pi$.
Fourier-Bessel expansions, often used in separation of variables calculations
for PDEs, are given by the same expansion above in~\eqref{eq:expan}, but the
frequencies~$\rho_j$ are chosen to be the ordered roots of~$J_0$. In the most
restrictive case, as discussed in~\cite{johnson1987}, the frequencies~$\rho_j$
are set to be the ordered roots of~$J_0$, and the nodes~$r_k$ are set to be
scaled roots of~$J_0$, i.e.~$r_k = \rho_k/\rho_{M+1}$, where~$\rho_{M+1}$ is
the~$(M+1)$th largest root of~$J_0$ (which doesn't explicitly appear in the sum
above). Analogues of all these special cases exist when~$J_0$ is replaced with a
higher order bessel function~$J_m$ as well, but we do not go into the details as
our algorithm handles them all similarly.

\subsection*{Existing methods}
\label{sec:existing}

A number of methods exist in the literature to evaluate (\ref{eq:HT}) and
(\ref{eq:DHT}). These include series expansion methods
\cite{lord1954b,brunol1977fourier,cavanagh1979numerical}, convolutional
approaches \cite{siegman1977quasi, johansen1979fast, mook1983algorithm,
liu1999nonuniform}, and projection-slice or Abel transform-based methods
\cite{oppenheim1980computation, hansen1985fast, kapur1995algorithm}.
See~\cite{cree1993algorithms} for a review of many of these early computational
approaches. Unfortunately, these existing methods are either not applicable to
the discrete case, require a particular choice of $\rho_j$ or $r_k$ due to the
constraints of interpolation or quadrature subroutines, or suffer from low
accuracy as a result of intermediate approximations. Therefore, extending these
schemes to compute the fully nonuniform DHT with controllable accuracy is not
straightforward.

More recently, butterfly algorithms \cite{oneil2010algorithm, li2015butterfly,
pang2020interpolative} were introduced as a broadly applicable methodology for
rapidly computing oscillatory transforms including the nonuniform DHT. However,
these algorithms require a precomputation or factorization stage for each new
set of $\rho_j$ and $r_k$. Such precomputations can, unfortunately, be a
bottleneck for applications in which these evaluation points change with each
iteration or application of the transform. In order to provide a
precomputation-free fast DHT,~\cite{townsend2015fast} employs a combination of
asymptotic expansions and Bessel function identities evaluated using the
equispaced FFT. The resulting scheme is applicable to equispaced or perturbed
``quasi-equispaced'' grids, for example $j_{0,k} / j_{0,n+1}$ where $j_{\nu,k}$
is the $k^{th}$ zero of $J_\nu$.



\subsection*{Novelty of this work}
\label{sec:novelty}

At a high level, our algorithm can be viewed as a generalization of the one
described in~\cite{townsend2015fast}. In~\cite{townsend2015fast}, asymptotic
expansions were used to replace~$J_0$ for various arguments. These asymptotic
expansions involved trigonometic functions, resulting in a fast algorithm for
computing the DHT using fast cosine transforms (FCTs) and fast sine transforms
(FSTs). In order to invoke these fast algorithms, various assumptions
on~$\rho_j$ and~$r_k$ had to be made.

{\color{red} Need to consolidate $\omega$, $\rho$ notation and decide if we're
doing integration in space or frequency, just to be consistent.}

We describe here a precomputation-free NonUniform Fast Hankel Transform (NUFHT)
which generalizes~\cite{townsend2015fast} to the fully nonuniform setting in a
number of ways. First, we employ an adaptive partitioning scheme which, for any
choice of $\rho_j$ and $r_k$, subdivides the matrix with entries~$J_0(\rho_j r_k)$ into blocks for which
matrix-vector products can be evaluated efficiently. Second, we use the
nonuniform fast Fourier transform (NUFFT)~\cite{dutt1993fast,
greengard2004accelerating} to evaluate asymptotic expansions for nonuniform
$r_k$ and $\omega_j$. Finally, we utilize the low-rank expansion of $J_\nu$
given by \cite{wimp1962polynomial} in the local regime where asymptotic
expansions are not applicable. We derive error bounds for this low-rank
expansion, allowing us to choose all approximation parameters automatically by
analysis which guarantees that the resulting error is bounded by the
user-specified tolerance $\epsilon$.

\subsection*{Outline of the paper}

The paper is organized as follows. In Section~\ref{sec:overview}, we give a high
level view of our algorithm, omitting technical details. Then in
Section~\ref{sec:approx} we outline the local and asymptotic expansions of
Bessel functions which serve as the key building blocks of the algorithm.
Afterward, in Section~\ref{sec:methods} we provide a detailed description of the
algorithm and its associated complexity. Various numerical examples are provided
in Section~\ref{sec:results}, and we conclude with some additional discussion in
Section~\ref{sec:discussion}.


%%% Local Variables: %% mode: latex %% TeX-master: "../main" %% End:
